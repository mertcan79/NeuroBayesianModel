{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "# Add the parent directory to sys.path\n",
    "notebook_dir = os.path.abspath('')\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from scipy.stats import rv_continuous, rv_discrete\n",
    "\n",
    "\n",
    "from src.data_processing import prepare_data, load_data\n",
    "from src.modeling import BayesianModel\n",
    "from src.inference import Inference\n",
    "from src.bayesian_node import BayesianNode, CategoricalNode\n",
    "from src.bayesian_network import BayesianNetwork\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from src.data_processing import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Determine environment and data path\n",
    "environment = os.getenv('ENVIRONMENT', 'local')\n",
    "data_path = os.getenv('LOCAL_DATA_PATH') if environment == 'local' else os.getenv('CLOUD_DATA_PATH')\n",
    "processed_data_path = os.getenv('LOCAL_DATA_PATH_PROCESSED') if environment == 'local' else os.getenv('CLOUD_DATA_PATH')\n",
    "\n",
    "# File paths\n",
    "behavioral_path = os.path.join(data_path, 'connectome_behavioral.csv')\n",
    "behavioral_path_processed = os.path.join(processed_data_path, 'connectome_behavioral.csv')\n",
    "\n",
    "\n",
    "hcp_path = os.path.join(data_path, 'hcp_freesurfer.csv')\n",
    "hcp_path_processed = os.path.join(processed_data_path, 'hcp_freesurfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_features = [\n",
    "    'Subject', 'Age', 'Gender', 'CogFluidComp_Unadj', 'CogCrystalComp_Unadj', 'MMSE_Score',\n",
    "    'NEOFAC_O', 'NEOFAC_C', 'ProcSpeed_Unadj', 'CardSort_Unadj', 'PicVocab_Unadj', 'ReadEng_Unadj'\n",
    "]\n",
    "\n",
    "hcp_features = [\n",
    "    'Subject', 'FS_TotCort_GM_Vol', 'FS_SubCort_GM_Vol', 'FS_Total_GM_Vol', 'FS_Tot_WM_Vol', 'FS_BrainStem_Vol',\n",
    "    'FS_L_Hippo_Vol', 'FS_R_Hippo_Vol', 'FS_L_Amygdala_Vol', 'FS_R_Amygdala_Vol',\n",
    "    'FS_L_Caudate_Vol', 'FS_R_Caudate_Vol', 'FS_L_Putamen_Vol', 'FS_R_Putamen_Vol',\n",
    "]\n",
    "\n",
    "categorical_columns = ['Age', 'Gender']\n",
    "\n",
    "prior_edges = [\n",
    "    ('Age', 'CogFluidComp_Unadj'),\n",
    "    ('Age', 'CogCrystalComp_Unadj'),\n",
    "    ('Age', 'MMSE_Score'),\n",
    "    ('Gender', 'CogFluidComp_Unadj'),\n",
    "    ('Gender', 'CogCrystalComp_Unadj'),\n",
    "    ('MMSE_Score', 'CogFluidComp_Unadj'),\n",
    "    ('MMSE_Score', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_Total_GM_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_Total_GM_Vol', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_Tot_WM_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_Tot_WM_Vol', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_L_Hippo_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_R_Hippo_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_L_Amygdala_Vol', 'NEOFAC_O'),\n",
    "    ('FS_R_Amygdala_Vol', 'NEOFAC_O'),\n",
    "    ('NEOFAC_O', 'CogCrystalComp_Unadj'),\n",
    "    ('NEOFAC_C', 'CogFluidComp_Unadj'),\n",
    "    ('FS_L_Hippo_Vol', 'NEOFAC_O'),\n",
    "    ('FS_R_Hippo_Vol', 'NEOFAC_O'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_age_to_category(age_str):\n",
    "    # Define age bins and corresponding ordinal categories\n",
    "    bins = ['22-25', '26-30', '31-35', '36+']\n",
    "    categories = [1, 2, 3, 4]  # Assigning ordinal values to age ranges\n",
    "    \n",
    "    if pd.isna(age_str):\n",
    "        return np.nan\n",
    "    age_str = age_str.strip()\n",
    "    \n",
    "    if age_str in bins:\n",
    "        return categories[bins.index(age_str)]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def process_age_gender(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'Age' in data.columns and data['Age'].dtype == 'object':\n",
    "        data['Age'] = data['Age'].apply(map_age_to_category)\n",
    "    return data\n",
    "\n",
    "# Load your data\n",
    "behavioral_data = pd.read_csv(behavioral_path)\n",
    "hcp_data = pd.read_csv(hcp_path)\n",
    "# Process Age column\n",
    "behavioral_data = process_age_gender(behavioral_data)\n",
    "\n",
    "# You can now save the processed data back to CSV if needed or pass it directly to prepare_data\n",
    "behavioral_data.to_csv('/Users/macbookair/Documents/NeuroBayesianModel/data/processed/connectome_behavioral.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call prepare_data\n",
    "data, categorical_columns, categories = prepare_data(\n",
    "    behavioral_path=behavioral_path_processed,\n",
    "    hcp_path=hcp_path_processed,\n",
    "    behavioral_features=behavioral_features,\n",
    "    hcp_features=hcp_features,\n",
    "    categorical_columns=categorical_columns,\n",
    "    index='Subject'\n",
    ")\n",
    "\n",
    "data = data.sample(n=100, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Types:\n",
      "FS_TotCort_GM_Vol       float64\n",
      "FS_SubCort_GM_Vol       float64\n",
      "FS_Total_GM_Vol         float64\n",
      "FS_Tot_WM_Vol           float64\n",
      "FS_BrainStem_Vol        float64\n",
      "FS_L_Hippo_Vol          float64\n",
      "FS_R_Hippo_Vol          float64\n",
      "FS_L_Amygdala_Vol       float64\n",
      "FS_R_Amygdala_Vol       float64\n",
      "FS_L_Caudate_Vol        float64\n",
      "FS_R_Caudate_Vol        float64\n",
      "FS_L_Putamen_Vol        float64\n",
      "FS_R_Putamen_Vol        float64\n",
      "Age                        int8\n",
      "Gender                     int8\n",
      "CogFluidComp_Unadj      float64\n",
      "CogCrystalComp_Unadj    float64\n",
      "MMSE_Score              float64\n",
      "NEOFAC_O                float64\n",
      "NEOFAC_C                float64\n",
      "ProcSpeed_Unadj         float64\n",
      "CardSort_Unadj          float64\n",
      "PicVocab_Unadj          float64\n",
      "ReadEng_Unadj           float64\n",
      "dtype: object\n",
      "\n",
      "Nodes in the Network:\n",
      "Node Name: FS_TotCort_GM_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_SubCort_GM_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_Total_GM_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_Tot_WM_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_BrainStem_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_L_Hippo_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_R_Hippo_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_L_Amygdala_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_R_Amygdala_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_L_Caudate_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_R_Caudate_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_L_Putamen_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: FS_R_Putamen_Vol, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: Age, Node Type: <class 'bayesian_node.CategoricalNode'>\n",
      "Node Name: Gender, Node Type: <class 'bayesian_node.CategoricalNode'>\n",
      "Node Name: CogFluidComp_Unadj, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: CogCrystalComp_Unadj, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: MMSE_Score, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: NEOFAC_O, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: NEOFAC_C, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: ProcSpeed_Unadj, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: CardSort_Unadj, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: PicVocab_Unadj, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "Node Name: ReadEng_Unadj, Node Type: <class 'bayesian_node.BayesianNode'>\n",
      "\n",
      "Age Node Details:\n",
      "Categories: [1, 0, 2, 3]\n",
      "Fitted: True\n",
      "\n",
      "Error computing sensitivity: Unsupported distribution type for node Age\n",
      "Age Node Details: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     sensitivity \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_sensitivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_node_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSensitivity:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sensitivity)\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/bayesian_network.py:107\u001b[0m, in \u001b[0;36mBayesianNetwork.compute_sensitivity\u001b[0;34m(self, target_node_name, num_samples)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Sample data for the target node\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m target_samples \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_node_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m sensitivities \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:32\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     31\u001b[0m parents \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mparents\n\u001b[0;32m---> 32\u001b[0m parent_samples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[1;32m     33\u001b[0m parent_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(parent_samples)\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:32\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     31\u001b[0m parents \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mparents\n\u001b[0;32m---> 32\u001b[0m parent_samples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[1;32m     33\u001b[0m parent_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(parent_samples)\n",
      "    \u001b[0;31m[... skipping similar frames: Inference.sample_node at line 32 (6 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:32\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     31\u001b[0m parents \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mparents\n\u001b[0;32m---> 32\u001b[0m parent_samples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[1;32m     33\u001b[0m parent_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(parent_samples)\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:36\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m parent_values \u001b[38;5;241m@\u001b[39m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m], size\u001b[38;5;241m=\u001b[39msize)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported distribution type for node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported distribution type for node Age",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mError computing sensitivity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m age_node:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAge Node Details:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_node\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/bayesian_node.py:23\u001b[0m, in \u001b[0;36mBayesianNode.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesianNode(name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, distribution=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, parents=\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparents\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/bayesian_node.py:23\u001b[0m, in \u001b[0;36mBayesianNode.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesianNode(name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, distribution=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, parents=\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparents\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: BayesianNode.__repr__ at line 23 (14 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/bayesian_node.py:23\u001b[0m, in \u001b[0;36mBayesianNode.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesianNode(name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, distribution=\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m, parents=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparents\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check DataFrame structure\n",
    "print(\"DataFrame Types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = BayesianModel(method='nsl', max_parents=4, iterations=100, categorical_columns=categorical_columns)\n",
    "try:\n",
    "    model.fit(data, prior_edges=prior_edges)\n",
    "except ValueError as e:\n",
    "    print(f\"Error fitting the model: {e}\")\n",
    "    # Additional debugging information\n",
    "    print(\"Data columns:\", data.columns)\n",
    "    print(\"Categorical columns:\", categorical_columns)\n",
    "\n",
    "# Extract nodes from the fitted model\n",
    "nodes = model.network.nodes\n",
    "\n",
    "# Verify node creation\n",
    "print(\"\\nNodes in the Network:\")\n",
    "for node_name, node in nodes.items():\n",
    "    print(f\"Node Name: {node_name}, Node Type: {type(node)}\")\n",
    "\n",
    "# Check CategoricalNode setup\n",
    "age_node = nodes.get('Age')\n",
    "if age_node:\n",
    "    print(\"\\nAge Node Details:\")\n",
    "    print(f\"Categories: {age_node.categories}\")\n",
    "    print(f\"Fitted: {age_node.fitted}\")\n",
    "\n",
    "target_node_name = \"Age\"  # or any other node name\n",
    "try:\n",
    "    sensitivities = model.network.compute_sensitivity(target_node_name)\n",
    "    print(\"Sensitivities:\", sensitivities)\n",
    "except ValueError as e:\n",
    "    print(f\"Error computing sensitivity: {e}\")\n",
    "\n",
    "# Check sensitivity computation\n",
    "target_node_name = \"CogFluidComp_Unadj\"\n",
    "try:\n",
    "    sensitivity = model.network.compute_sensitivity(target_node_name)\n",
    "    print(\"\\nSensitivity:\", sensitivity)\n",
    "except ValueError as e:\n",
    "    print(f\"\\nError computing sensitivity: {e}\")\n",
    "    if age_node:\n",
    "        print(\"Age Node Details:\", age_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 'CogFluidComp_Unadj' found in the network.\n",
      "Error computing sensitivity: Unsupported distribution type for node Age\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "model = BayesianModel(method='nsl', max_parents=4, iterations=100, categorical_columns=categorical_columns)\n",
    "try:\n",
    "    model.fit(data, prior_edges=prior_edges)\n",
    "except ValueError as e:\n",
    "    print(f\"Error fitting the model: {e}\")\n",
    "    # Additional debugging information\n",
    "    print(\"Data columns:\", data.columns)\n",
    "    print(\"Categorical columns:\", categorical_columns)\n",
    "\n",
    "# Extract nodes from the fitted model\n",
    "nodes = model.network.nodes\n",
    "\n",
    "# Verify node existence in the network\n",
    "target_node_name = \"CogFluidComp_Unadj\"\n",
    "if target_node_name in nodes:\n",
    "    print(f\"Node '{target_node_name}' found in the network.\")\n",
    "    try:\n",
    "        sensitivity = model.network.compute_sensitivity(target_node_name)\n",
    "        print(\"Sensitivity:\", sensitivity)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error computing sensitivity: {e}\")\n",
    "else:\n",
    "    print(f\"Node '{target_node_name}' NOT found in the network.\")\n",
    "    print(\"Available nodes in the network:\", list(nodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported distribution type for node Age",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sensitivities\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m sensitivity \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_sensitivity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCogFluidComp_Unadj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(sensitivity)\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/bayesian_network.py:107\u001b[0m, in \u001b[0;36mBayesianNetwork.compute_sensitivity\u001b[0;34m(self, target_node_name, num_samples)\u001b[0m\n\u001b[1;32m    104\u001b[0m inference \u001b[38;5;241m=\u001b[39m Inference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Sample data for the target node\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m target_samples \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_node_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m sensitivities \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_name, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:32\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m distribution:\n\u001b[1;32m     31\u001b[0m     parents \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mparents\n\u001b[0;32m---> 32\u001b[0m     parent_samples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[1;32m     33\u001b[0m     parent_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(parent_samples)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m parent_values \u001b[38;5;241m@\u001b[39m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m], size\u001b[38;5;241m=\u001b[39msize)\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:32\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m distribution:\n\u001b[1;32m     31\u001b[0m     parents \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mparents\n\u001b[0;32m---> 32\u001b[0m     parent_samples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[1;32m     33\u001b[0m     parent_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(parent_samples)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m parent_values \u001b[38;5;241m@\u001b[39m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m], size\u001b[38;5;241m=\u001b[39msize)\n",
      "    \u001b[0;31m[... skipping similar frames: Inference.sample_node at line 32 (10 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:32\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m distribution:\n\u001b[1;32m     31\u001b[0m     parents \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mparents\n\u001b[0;32m---> 32\u001b[0m     parent_samples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents]\n\u001b[1;32m     33\u001b[0m     parent_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(parent_samples)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m parent_values \u001b[38;5;241m@\u001b[39m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m], size\u001b[38;5;241m=\u001b[39msize)\n",
      "File \u001b[0;32m~/Documents/NeuroBayesianModel/src/inference.py:36\u001b[0m, in \u001b[0;36mInference.sample_node\u001b[0;34m(self, node_name, size, depth, visited)\u001b[0m\n\u001b[1;32m     33\u001b[0m         parent_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(parent_samples)\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m parent_values \u001b[38;5;241m@\u001b[39m distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m], size\u001b[38;5;241m=\u001b[39msize)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported distribution type for node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported distribution type for node Age"
     ]
    }
   ],
   "source": [
    "# Compute sensitivity using Inference class\n",
    "def compute_sensitivity(network: BayesianNetwork, target_node_name: str, num_samples: int = 1000) -> Dict[str, float]:\n",
    "    if target_node_name not in network.nodes:\n",
    "        raise ValueError(f\"Node {target_node_name} not found in the network.\")\n",
    "    \n",
    "    # Sample data for the target node\n",
    "    target_samples = inference.sample_node(target_node_name, num_samples)\n",
    "    \n",
    "    # Compute sensitivity\n",
    "    sensitivities = {}\n",
    "    for node_name, node in network.nodes.items():\n",
    "        if node_name == target_node_name:\n",
    "            continue\n",
    "        \n",
    "        # Sample for other nodes\n",
    "        other_samples = inference.sample_node(node_name, num_samples)\n",
    "        \n",
    "        # Compute sensitivity (example: mean difference or correlation)\n",
    "        sensitivity = np.mean(target_samples) - np.mean(other_samples)\n",
    "        sensitivities[node_name] = sensitivity\n",
    "    \n",
    "    return sensitivities\n",
    "\n",
    "# Example usage\n",
    "sensitivity = model.network.compute_sensitivity(\"CogFluidComp_Unadj\")\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sampling node: Node CogFluidComp_Unadj not found in the network.\n",
      "Failed to sample node CogFluidComp_Unadj\n"
     ]
    }
   ],
   "source": [
    "def sample_node_with_inference(node_name: str, size: int = 1) -> np.ndarray:\n",
    "    try:\n",
    "        samples = inference.sample_node(node_name, size)\n",
    "        return samples\n",
    "    except Exception as e:\n",
    "        print(f\"Error sampling node: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test sampling a node\n",
    "node_name = 'CogFluidComp_Unadj'\n",
    "samples = sample_node_with_inference(node_name, size=1000)\n",
    "\n",
    "if samples is not None:\n",
    "    print(f\"Samples for {node_name}: {samples[:10]}\")  # Print the first 10 samples\n",
    "else:\n",
    "    print(f\"Failed to sample node {node_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = inference.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Initialization Check\n",
      "Node Name: FS_TotCort_GM_Vol, Type: BayesianNode\n",
      "Node Name: FS_SubCort_GM_Vol, Type: BayesianNode\n",
      "Node Name: FS_Total_GM_Vol, Type: BayesianNode\n",
      "Node Name: FS_Tot_WM_Vol, Type: BayesianNode\n",
      "Node Name: FS_BrainStem_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Hippo_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Hippo_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Amygdala_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Amygdala_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Caudate_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Caudate_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Putamen_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Putamen_Vol, Type: BayesianNode\n",
      "Node Name: Age, Type: BayesianNode\n",
      "Node Name: Gender, Type: BayesianNode\n",
      "Node Name: CogFluidComp_Unadj, Type: BayesianNode\n",
      "Node Name: CogCrystalComp_Unadj, Type: BayesianNode\n",
      "Node Name: MMSE_Score, Type: BayesianNode\n",
      "Node Name: NEOFAC_O, Type: BayesianNode\n",
      "Node Name: NEOFAC_C, Type: BayesianNode\n",
      "Node Name: ProcSpeed_Unadj, Type: BayesianNode\n",
      "Node Name: CardSort_Unadj, Type: BayesianNode\n",
      "Node Name: PicVocab_Unadj, Type: BayesianNode\n",
      "Node Name: ReadEng_Unadj, Type: BayesianNode\n",
      "\n",
      "Distributions Check\n",
      "Error with node FS_TotCort_GM_Vol: name 'stats' is not defined\n",
      "Error with node FS_SubCort_GM_Vol: name 'stats' is not defined\n",
      "Error with node FS_Total_GM_Vol: name 'stats' is not defined\n",
      "Error with node FS_Tot_WM_Vol: name 'stats' is not defined\n",
      "Error with node FS_BrainStem_Vol: name 'stats' is not defined\n",
      "Error with node FS_L_Hippo_Vol: name 'stats' is not defined\n",
      "Error with node FS_R_Hippo_Vol: name 'stats' is not defined\n",
      "Error with node FS_L_Amygdala_Vol: name 'stats' is not defined\n",
      "Error with node FS_R_Amygdala_Vol: name 'stats' is not defined\n",
      "Error with node FS_L_Caudate_Vol: name 'stats' is not defined\n",
      "Error with node FS_R_Caudate_Vol: name 'stats' is not defined\n",
      "Error with node FS_L_Putamen_Vol: name 'stats' is not defined\n",
      "Error with node FS_R_Putamen_Vol: name 'stats' is not defined\n",
      "Error with node Age: name 'stats' is not defined\n",
      "Error with node Gender: name 'stats' is not defined\n",
      "Error with node CogFluidComp_Unadj: name 'stats' is not defined\n",
      "Error with node CogCrystalComp_Unadj: name 'stats' is not defined\n",
      "Error with node MMSE_Score: name 'stats' is not defined\n",
      "Error with node NEOFAC_O: name 'stats' is not defined\n",
      "Error with node NEOFAC_C: name 'stats' is not defined\n",
      "Error with node ProcSpeed_Unadj: name 'stats' is not defined\n",
      "Error with node CardSort_Unadj: name 'stats' is not defined\n",
      "Error with node PicVocab_Unadj: name 'stats' is not defined\n",
      "Error with node ReadEng_Unadj: name 'stats' is not defined\n",
      "\n",
      "Network Structure Check\n",
      "\n",
      "Inference Test\n",
      "Samples for CogFluidComp_Unadj: [ 0.95523927  0.40232437  0.48835562  1.86438911  0.64413196 -0.30130443\n",
      " -0.78681586 -0.39646575 -0.19437846 -0.50648209]\n",
      "Sensitivity for CogFluidComp_Unadj: {'FS_TotCort_GM_Vol': 0.09011243338323295, 'FS_SubCort_GM_Vol': 0.05442333326431852, 'FS_Total_GM_Vol': 0.12756956069562916, 'FS_Tot_WM_Vol': 0.06277465999327103, 'FS_BrainStem_Vol': -0.03604019054635843, 'FS_L_Hippo_Vol': -0.010306111598529052, 'FS_R_Hippo_Vol': 0.022424127586708503, 'FS_L_Amygdala_Vol': 0.0004260983817248182, 'FS_R_Amygdala_Vol': 0.11792165124831216, 'FS_L_Caudate_Vol': 0.07263501272709395, 'FS_R_Caudate_Vol': 0.08312969918980127, 'FS_L_Putamen_Vol': 0.13392170453581292, 'FS_R_Putamen_Vol': 0.06734544874776627, 'Age': -1.083827350858431, 'Gender': -0.36906064100083985, 'CogCrystalComp_Unadj': -0.0718609441612437, 'MMSE_Score': -28.996360517428815, 'NEOFAC_O': 0.02790227403910253, 'NEOFAC_C': 0.09373747695818177, 'ProcSpeed_Unadj': 0.007884637537740838, 'CardSort_Unadj': -0.04699190208987196, 'PicVocab_Unadj': 0.042536299716846374, 'ReadEng_Unadj': -0.07723950255695022}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Verify Node Initialization\n",
    "print(\"Node Initialization Check\")\n",
    "for node_name, node in nodes.items():\n",
    "    if isinstance(node, BayesianNode):\n",
    "        print(f\"Node Name: {node_name}, Type: BayesianNode\")\n",
    "    else:\n",
    "        print(f\"Node Name: {node_name}, Type: {type(node).__name__}\")\n",
    "\n",
    "# 2. Check Distributions for Nodes\n",
    "print(\"\\nDistributions Check\")\n",
    "for node_name, node in nodes.items():\n",
    "    try:\n",
    "        distribution = node.get_distribution()\n",
    "        if isinstance(distribution, (stats.rv_continuous, stats.rv_discrete)):\n",
    "            print(f\"Node Name: {node_name}\")\n",
    "            print(f\"Distribution: {distribution}\")\n",
    "            print(f\"Distribution Type: {type(distribution).__name__}\")\n",
    "            samples = distribution.rvs(size=10)\n",
    "            print(f\"Samples: {samples}\")\n",
    "        else:\n",
    "            print(f\"Node {node_name} has an unsupported distribution type: {type(distribution).__name__}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with node {node_name}: {e}\")\n",
    "\n",
    "# 3. Verify Network Structure\n",
    "print(\"\\nNetwork Structure Check\")\n",
    "try:\n",
    "    # Check if network structure is properly defined\n",
    "    for node_name, node in nodes.items():\n",
    "        if not hasattr(node, 'children'):\n",
    "            print(f\"Node {node_name} is missing 'children' attribute.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"Network Structure Error: {e}\")\n",
    "\n",
    "# 4. Test Inference Class\n",
    "print(\"\\nInference Test\")\n",
    "try:\n",
    "    # Test sampling from a node\n",
    "    node_name = 'CogFluidComp_Unadj'\n",
    "    try:\n",
    "        samples = inference.sample_node(node_name, size=10)\n",
    "        print(f\"Samples for {node_name}: {samples}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Sampling Error: {ve}\")\n",
    "    \n",
    "    # Test sensitivity computation (assuming compute_sensitivity function exists)\n",
    "    try:\n",
    "        sensitivity = compute_sensitivity(network, node_name)  # Ensure 'network' is defined\n",
    "        print(f\"Sensitivity for {node_name}: {sensitivity}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Sensitivity Computation Error: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Inference Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
