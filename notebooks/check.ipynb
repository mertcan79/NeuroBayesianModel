{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "# Add the parent directory to sys.path\n",
    "notebook_dir = os.path.abspath('')\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from scipy.stats import rv_continuous, rv_discrete\n",
    "\n",
    "\n",
    "from src.data_processing import prepare_data\n",
    "from src.modeling import BayesianModel\n",
    "from src.inference import Inference\n",
    "from src.bayesian_node import BayesianNode, CategoricalNode\n",
    "from src.bayesian_network import BayesianNetwork\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from src.data_processing import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Determine environment and data path\n",
    "environment = os.getenv('ENVIRONMENT', 'local')\n",
    "data_path = os.getenv('LOCAL_DATA_PATH') if environment == 'local' else os.getenv('CLOUD_DATA_PATH')\n",
    "\n",
    "# File paths\n",
    "behavioral_path = os.path.join(data_path, 'connectome_behavioral.csv')\n",
    "hcp_path = os.path.join(data_path, 'hcp_freesurfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_hcp = ['Gender', 'MMSE_Score', 'Age']\n",
    "\n",
    "behavioral_features = [\n",
    "    'Subject', 'Age', 'Gender', 'CogFluidComp_Unadj', 'CogCrystalComp_Unadj', 'MMSE_Score',\n",
    "    'NEOFAC_O', 'NEOFAC_C', 'ProcSpeed_Unadj', 'CardSort_Unadj', 'PicVocab_Unadj', 'ReadEng_Unadj'\n",
    "]\n",
    "\n",
    "hcp_features = [\n",
    "    'Subject', 'FS_TotCort_GM_Vol', 'FS_SubCort_GM_Vol', 'FS_Total_GM_Vol', 'FS_Tot_WM_Vol', 'FS_BrainStem_Vol',\n",
    "    'FS_L_Hippo_Vol', 'FS_R_Hippo_Vol', 'FS_L_Amygdala_Vol', 'FS_R_Amygdala_Vol',\n",
    "    'FS_L_Caudate_Vol', 'FS_R_Caudate_Vol', 'FS_L_Putamen_Vol', 'FS_R_Putamen_Vol',\n",
    "]\n",
    "\n",
    "categorical_columns = ['Gender', 'MMSE_Score', 'Age']\n",
    "\n",
    "prior_edges = [\n",
    "    ('Age', 'CogFluidComp_Unadj'),\n",
    "    ('Age', 'CogCrystalComp_Unadj'),\n",
    "    ('Age', 'MMSE_Score'),\n",
    "    ('Gender', 'CogFluidComp_Unadj'),\n",
    "    ('Gender', 'CogCrystalComp_Unadj'),\n",
    "    ('MMSE_Score', 'CogFluidComp_Unadj'),\n",
    "    ('MMSE_Score', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_Total_GM_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_Total_GM_Vol', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_Tot_WM_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_Tot_WM_Vol', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_L_Hippo_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_R_Hippo_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_L_Amygdala_Vol', 'NEOFAC_O'),\n",
    "    ('FS_R_Amygdala_Vol', 'NEOFAC_O'),\n",
    "    ('NEOFAC_O', 'CogCrystalComp_Unadj'),\n",
    "    ('NEOFAC_C', 'CogFluidComp_Unadj'),\n",
    "    ('FS_L_Hippo_Vol', 'NEOFAC_O'),\n",
    "    ('FS_R_Hippo_Vol', 'NEOFAC_O'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, categorical_columns, categories = prepare_data(\n",
    "    behavioral_path=behavioral_path,\n",
    "    hcp_path=hcp_path,\n",
    "    behavioral_features=behavioral_features,\n",
    "    hcp_features=hcp_features,\n",
    "    categorical_columns=categorical_columns_hcp\n",
    "    )\n",
    "\n",
    "data = data.sample(n=200, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "model = BayesianModel(method='k2', max_parents=2, iterations=100, categorical_columns=categorical_columns)\n",
    "model.fit(data, prior_edges=prior_edges)\n",
    "\n",
    "# Access the Bayesian Network and Inference\n",
    "network = model.network\n",
    "inference = model.inference  # This should now be correctly initialized with nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute sensitivity using Inference class\n",
    "def compute_sensitivity(network: BayesianNetwork, target_node_name: str, num_samples: int = 1000) -> Dict[str, float]:\n",
    "    if target_node_name not in network.nodes:\n",
    "        raise ValueError(f\"Node {target_node_name} not found in the network.\")\n",
    "    \n",
    "    # Sample data for the target node\n",
    "    target_samples = inference.sample_node(target_node_name, num_samples)\n",
    "    \n",
    "    # Compute sensitivity\n",
    "    sensitivities = {}\n",
    "    for node_name, node in network.nodes.items():\n",
    "        if node_name == target_node_name:\n",
    "            continue\n",
    "        \n",
    "        # Sample for other nodes\n",
    "        other_samples = inference.sample_node(node_name, num_samples)\n",
    "        \n",
    "        # Compute sensitivity (example: mean difference or correlation)\n",
    "        sensitivity = np.mean(target_samples) - np.mean(other_samples)\n",
    "        sensitivities[node_name] = sensitivity\n",
    "    \n",
    "    return sensitivities\n",
    "\n",
    "# Example usage\n",
    "sensitivity = compute_sensitivity(network, \"CogFluidComp_Unadj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples for CogFluidComp_Unadj: [-1.94868927  2.07335034 -0.14905911  0.91223995 -0.59371019  2.44416619\n",
      "  0.12702616 -0.84815402  0.81423897 -0.23063329]\n"
     ]
    }
   ],
   "source": [
    "def sample_node_with_inference(node_name: str, size: int = 1) -> np.ndarray:\n",
    "    try:\n",
    "        samples = inference.sample_node(node_name, size)\n",
    "        return samples\n",
    "    except Exception as e:\n",
    "        print(f\"Error sampling node: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test sampling a node\n",
    "node_name = 'CogFluidComp_Unadj'\n",
    "samples = sample_node_with_inference(node_name, size=1000)\n",
    "\n",
    "if samples is not None:\n",
    "    print(f\"Samples for {node_name}: {samples[:10]}\")  # Print the first 10 samples\n",
    "else:\n",
    "    print(f\"Failed to sample node {node_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241m.\u001b[39mnodes\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Verify Node Initialization\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode Initialization Check\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inference' is not defined"
     ]
    }
   ],
   "source": [
    "nodes = inference.nodes\n",
    "\n",
    "# 1. Verify Node Initialization\n",
    "print(\"Node Initialization Check\")\n",
    "for node_name, node in nodes.items():\n",
    "    if isinstance(node, BayesianNode):\n",
    "        print(f\"Node Name: {node_name}, Type: BayesianNode\")\n",
    "    else:\n",
    "        print(f\"Node Name: {node_name}, Type: {type(node).__name__}\")\n",
    "\n",
    "# 2. Check Distributions for Nodes\n",
    "print(\"\\nDistributions Check\")\n",
    "for node_name, node in nodes.items():\n",
    "    try:\n",
    "        distribution = node.get_distribution()\n",
    "        if isinstance(distribution, rv_continuous):\n",
    "            print(f\"Node Name: {node_name}\")\n",
    "            print(f\"Distribution: {distribution}\")\n",
    "            print(f\"Distribution Type: {type(distribution).__name__}\")\n",
    "            samples = distribution.rvs(size=10)  # Sample from the distribution\n",
    "            print(f\"Samples: {samples}\")\n",
    "        else:\n",
    "            print(f\"Node {node_name} has an unsupported distribution type: {type(distribution).__name__}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with node {node_name}: {e}\")\n",
    "\n",
    "# 3. Verify Network Structure\n",
    "print(\"\\nNetwork Structure Check\")\n",
    "try:\n",
    "    # Check if network structure is properly defined\n",
    "    for node_name, node in nodes.items():\n",
    "        if not hasattr(node, 'children'):\n",
    "            print(f\"Node {node_name} is missing 'children' attribute.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"Network Structure Error: {e}\")\n",
    "\n",
    "# 4. Test Inference Class\n",
    "print(\"\\nInference Test\")\n",
    "try:\n",
    "    # Test sampling from a node\n",
    "    node_name = 'CogFluidComp_Unadj'\n",
    "    try:\n",
    "        samples = inference.sample_node(node_name, size=10)\n",
    "        print(f\"Samples for {node_name}: {samples}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Sampling Error: {ve}\")\n",
    "    \n",
    "    # Test sensitivity computation (assuming compute_sensitivity function exists)\n",
    "    try:\n",
    "        sensitivity = compute_sensitivity(network, node_name)  # Ensure 'network' is defined\n",
    "        print(f\"Sensitivity for {node_name}: {sensitivity}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Sensitivity Computation Error: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Inference Error: {e}\")\n",
    "\n",
    "# Note: Replace placeholder parts with actual implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
