{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "notebook_dir = os.path.abspath('')\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from scipy import stats\n",
    "import networkx as nx\n",
    "import json\n",
    "from pgmpy.estimators import PC\n",
    "from pgmpy.models import BayesianNetwork as PgmpyBN\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from datetime import datetime\n",
    "\n",
    "from src.bayesian_network import BayesianNetwork\n",
    "from src.bayesian_node import BayesianNode, CategoricalNode\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from src.data_processing import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data loaded successfully\n",
      "Features selected successfully\n",
      "Data merged successfully\n",
      "Merged data shape: (1113, 25)\n",
      "Original data types:\n",
      "Subject                   int64\n",
      "FS_TotCort_GM_Vol         int64\n",
      "FS_SubCort_GM_Vol         int64\n",
      "FS_Total_GM_Vol           int64\n",
      "FS_Tot_WM_Vol             int64\n",
      "FS_BrainStem_Vol          int64\n",
      "FS_L_Hippo_Vol            int64\n",
      "FS_R_Hippo_Vol            int64\n",
      "FS_L_Amygdala_Vol         int64\n",
      "FS_R_Amygdala_Vol         int64\n",
      "FS_L_Caudate_Vol          int64\n",
      "FS_R_Caudate_Vol          int64\n",
      "FS_L_Putamen_Vol          int64\n",
      "FS_R_Putamen_Vol          int64\n",
      "Age                      object\n",
      "Gender                   object\n",
      "CogFluidComp_Unadj      float64\n",
      "CogCrystalComp_Unadj    float64\n",
      "MMSE_Score                int64\n",
      "NEOFAC_O                float64\n",
      "NEOFAC_C                float64\n",
      "ProcSpeed_Unadj         float64\n",
      "CardSort_Unadj          float64\n",
      "PicVocab_Unadj          float64\n",
      "ReadEng_Unadj           float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "Subject                  0\n",
      "FS_TotCort_GM_Vol        0\n",
      "FS_SubCort_GM_Vol        0\n",
      "FS_Total_GM_Vol          0\n",
      "FS_Tot_WM_Vol            0\n",
      "FS_BrainStem_Vol         0\n",
      "FS_L_Hippo_Vol           0\n",
      "FS_R_Hippo_Vol           0\n",
      "FS_L_Amygdala_Vol        0\n",
      "FS_R_Amygdala_Vol        0\n",
      "FS_L_Caudate_Vol         0\n",
      "FS_R_Caudate_Vol         0\n",
      "FS_L_Putamen_Vol         0\n",
      "FS_R_Putamen_Vol         0\n",
      "Age                      0\n",
      "Gender                   0\n",
      "CogFluidComp_Unadj      16\n",
      "CogCrystalComp_Unadj     9\n",
      "MMSE_Score               0\n",
      "NEOFAC_O                 7\n",
      "NEOFAC_C                 7\n",
      "ProcSpeed_Unadj          0\n",
      "CardSort_Unadj           2\n",
      "PicVocab_Unadj           0\n",
      "ReadEng_Unadj            0\n",
      "dtype: int64\n",
      "\n",
      "Numeric columns: ['Subject', 'FS_TotCort_GM_Vol', 'FS_SubCort_GM_Vol', 'FS_Total_GM_Vol', 'FS_Tot_WM_Vol', 'FS_BrainStem_Vol', 'FS_L_Hippo_Vol', 'FS_R_Hippo_Vol', 'FS_L_Amygdala_Vol', 'FS_R_Amygdala_Vol', 'FS_L_Caudate_Vol', 'FS_R_Caudate_Vol', 'FS_L_Putamen_Vol', 'FS_R_Putamen_Vol', 'CogFluidComp_Unadj', 'CogCrystalComp_Unadj', 'NEOFAC_O', 'NEOFAC_C', 'ProcSpeed_Unadj', 'CardSort_Unadj', 'PicVocab_Unadj', 'ReadEng_Unadj']\n",
      "\n",
      "Final data types:\n",
      "Subject                 float64\n",
      "FS_TotCort_GM_Vol       float64\n",
      "FS_SubCort_GM_Vol       float64\n",
      "FS_Total_GM_Vol         float64\n",
      "FS_Tot_WM_Vol           float64\n",
      "FS_BrainStem_Vol        float64\n",
      "FS_L_Hippo_Vol          float64\n",
      "FS_R_Hippo_Vol          float64\n",
      "FS_L_Amygdala_Vol       float64\n",
      "FS_R_Amygdala_Vol       float64\n",
      "FS_L_Caudate_Vol        float64\n",
      "FS_R_Caudate_Vol        float64\n",
      "FS_L_Putamen_Vol        float64\n",
      "FS_R_Putamen_Vol        float64\n",
      "Age                        int8\n",
      "Gender                    int64\n",
      "CogFluidComp_Unadj      float64\n",
      "CogCrystalComp_Unadj    float64\n",
      "MMSE_Score                int64\n",
      "NEOFAC_O                float64\n",
      "NEOFAC_C                float64\n",
      "ProcSpeed_Unadj         float64\n",
      "CardSort_Unadj          float64\n",
      "PicVocab_Unadj          float64\n",
      "ReadEng_Unadj           float64\n",
      "dtype: object\n",
      "Data preprocessed successfully\n",
      "{'Gender': [0, 1], 'MMSE_Score': [23, 24, 26, 27, 28, 29, 30], 'Age': [0, 1, 2, 3]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4dbf912351482b9b1edbd9972bf486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in the Bayesian Network model:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "print(\"Preparing data...\")\n",
    "data, categorical_columns, categories = prepare_data()\n",
    "print(categories)\n",
    "# Use PC algorithm for structure learning\n",
    "pc = PC(data)\n",
    "edges = pc.estimate(significance_level=0.05)\n",
    "\n",
    "# Create a Bayesian Network using pgmpy\n",
    "model = PgmpyBN(edges)\n",
    "\n",
    "# Print out the nodes in the model\n",
    "print(\"Nodes in the Bayesian Network model:\")\n",
    "print(model.nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the parameters\n",
    "model.fit(data, estimator=BayesianEstimator, prior_type=\"BDeu\")\n",
    "\n",
    "# Perform inference\n",
    "inference = VariableElimination(model)\n",
    "\n",
    "# Gather unique values for each column\n",
    "unique_values = {col: data[col].unique().tolist() for col in data.columns}\n",
    "\n",
    "# Example: Predict CogFluidComp_Unadj given Age and Gender\n",
    "# Note: For comprehensive analysis, you might want to run this for all combinations\n",
    "predictions = {}\n",
    "\n",
    "# Check nodes in the model\n",
    "nodes_in_model = model.nodes()\n",
    "\n",
    "for age_category in unique_values['Age']:\n",
    "    for gender_category in unique_values['Gender']:\n",
    "        # Ensure all evidence nodes are in the model\n",
    "        if 'Age' in nodes_in_model and 'Gender' in nodes_in_model:\n",
    "            evidence = {'Age': age_category, 'Gender': gender_category}\n",
    "            try:\n",
    "                prediction = inference.query(['CogFluidComp_Unadj'], evidence=evidence)\n",
    "                predictions[f\"Age_{age_category}_Gender_{gender_category}\"] = str(prediction)\n",
    "            except Exception as e:\n",
    "                predictions[f\"Age_{age_category}_Gender_{gender_category}\"] = f\"Error: {str(e)}\"\n",
    "        else:\n",
    "            predictions[f\"Age_{age_category}_Gender_{gender_category}\"] = \"Error: Evidence node not in model\"\n",
    "\n",
    "# Gather influences\n",
    "influences = {node: model.get_parents(node) for node in model.nodes() if model.get_parents(node)}\n",
    "\n",
    "# Save results to JSON\n",
    "results = {\n",
    "    \"learned_structure\": [edge for edge in model.edges()],\n",
    "    \"unique_values\": unique_values,\n",
    "    \"predictions\": predictions,\n",
    "    \"influences\": influences\n",
    "}\n",
    "\n",
    "filename = f\"{datetime.now().strftime('%Y-%m-%d-%H-%M')}-findings.json\"\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_categorical_data(data, categorical_columns, categories):\n",
    "    issues = []\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col not in data.columns:\n",
    "            issues.append(f\"Column '{col}' not found in data\")\n",
    "            continue\n",
    "        \n",
    "        min_val = data[col].min()\n",
    "        if pd.api.types.is_numeric_dtype(data[col]) and min_val < 0:\n",
    "            issues.append(f\"Negative values found in categorical column '{col}'. Min value: {min_val}\")\n",
    "        \n",
    "        if col in categories:\n",
    "            unique_values = set(data[col].dropna().unique())\n",
    "            if not set(categories[col]).issuperset(unique_values):\n",
    "                issues.append(f\"Mismatch in categories for '{col}'. Data contains values not in specified categories.\")\n",
    "        else:\n",
    "            issues.append(f\"No categories specified for categorical column '{col}'\")\n",
    "    \n",
    "    return issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with problematic distributions:\n",
      "\n",
      "FS_TotCort_GM_Vol:\n",
      "  Skewness: 0.23\n",
      "  Kurtosis: -0.14\n",
      "  Shapiro-Wilk p-value: 0.0015\n",
      "\n",
      "FS_SubCort_GM_Vol:\n",
      "  Skewness: 0.21\n",
      "  Kurtosis: -0.15\n",
      "  Shapiro-Wilk p-value: 0.0014\n",
      "\n",
      "FS_Total_GM_Vol:\n",
      "  Skewness: 0.19\n",
      "  Kurtosis: -0.29\n",
      "  Shapiro-Wilk p-value: 0.0021\n",
      "\n",
      "FS_Tot_WM_Vol:\n",
      "  Skewness: 0.36\n",
      "  Kurtosis: 0.01\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "FS_BrainStem_Vol:\n",
      "  Skewness: 0.49\n",
      "  Kurtosis: 1.17\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "FS_L_Hippo_Vol:\n",
      "  Skewness: -0.14\n",
      "  Kurtosis: 2.08\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "FS_R_Hippo_Vol:\n",
      "  Skewness: 0.13\n",
      "  Kurtosis: 0.27\n",
      "  Shapiro-Wilk p-value: 0.0059\n",
      "\n",
      "FS_L_Amygdala_Vol:\n",
      "  Skewness: 0.37\n",
      "  Kurtosis: 0.01\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "FS_R_Amygdala_Vol:\n",
      "  Skewness: 0.50\n",
      "  Kurtosis: 0.80\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "FS_L_Caudate_Vol:\n",
      "  Skewness: 0.37\n",
      "  Kurtosis: 0.06\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "FS_R_Caudate_Vol:\n",
      "  Skewness: 0.36\n",
      "  Kurtosis: 0.12\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "Age:\n",
      "  Skewness: -0.11\n",
      "  Kurtosis: -0.92\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "Gender:\n",
      "  Skewness: -0.18\n",
      "  Kurtosis: -1.97\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "CogFluidComp_Unadj:\n",
      "  Skewness: 0.27\n",
      "  Kurtosis: -0.40\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "CogCrystalComp_Unadj:\n",
      "  Skewness: 0.05\n",
      "  Kurtosis: 0.13\n",
      "  Shapiro-Wilk p-value: 0.0050\n",
      "\n",
      "MMSE_Score:\n",
      "  Skewness: -1.14\n",
      "  Kurtosis: 1.53\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "NEOFAC_O:\n",
      "  Skewness: 0.23\n",
      "  Kurtosis: -0.15\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "NEOFAC_C:\n",
      "  Skewness: -0.39\n",
      "  Kurtosis: 0.26\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "ProcSpeed_Unadj:\n",
      "  Skewness: 0.24\n",
      "  Kurtosis: 0.35\n",
      "  Shapiro-Wilk p-value: 0.0000\n",
      "\n",
      "CardSort_Unadj:\n",
      "  Skewness: 0.20\n",
      "  Kurtosis: 0.24\n",
      "  Shapiro-Wilk p-value: 0.0001\n",
      "\n",
      "PicVocab_Unadj:\n",
      "  Skewness: 0.18\n",
      "  Kurtosis: 0.41\n",
      "  Shapiro-Wilk p-value: 0.0009\n",
      "\n",
      "ReadEng_Unadj:\n",
      "  Skewness: -0.16\n",
      "  Kurtosis: 0.18\n",
      "  Shapiro-Wilk p-value: 0.0001\n"
     ]
    }
   ],
   "source": [
    "def check_distributions(data):\n",
    "    problematic_columns = []\n",
    "    stats_dict = {}\n",
    "    cols_to_check = [col for col in data.columns if col != 'Subject']\n",
    "    for column in cols_to_check:\n",
    "        # Skip non-numeric columns\n",
    "        if not np.issubdtype(data[column].dtype, np.number):\n",
    "            continue\n",
    "\n",
    "        # Calculate statistics\n",
    "        skewness = stats.skew(data[column].dropna())\n",
    "        kurtosis = stats.kurtosis(data[column].dropna())\n",
    "        shapiro_test = stats.shapiro(data[column].dropna())\n",
    "\n",
    "        # Check for extreme values\n",
    "        is_problematic = (\n",
    "            abs(skewness) > 2 or \n",
    "            abs(kurtosis) > 7 or \n",
    "            shapiro_test.pvalue < 0.05\n",
    "        )\n",
    "\n",
    "        if is_problematic:\n",
    "            problematic_columns.append(column)\n",
    "            stats_dict[column] = {\n",
    "                'skewness': skewness,\n",
    "                'kurtosis': kurtosis,\n",
    "                'shapiro_pvalue': shapiro_test.pvalue\n",
    "            }\n",
    "\n",
    "    return problematic_columns, stats_dict\n",
    "\n",
    "# Assuming 'processed_data' is your DataFrame\n",
    "problematic_cols, stats = check_distributions(data)\n",
    "\n",
    "print(\"Columns with problematic distributions:\")\n",
    "for col in problematic_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Skewness: {stats[col]['skewness']:.2f}\")\n",
    "    print(f\"  Kurtosis: {stats[col]['kurtosis']:.2f}\")\n",
    "    print(f\"  Shapiro-Wilk p-value: {stats[col]['shapiro_pvalue']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
