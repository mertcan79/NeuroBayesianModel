{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "# Add the parent directory to sys.path\n",
    "notebook_dir = os.path.abspath('')\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from scipy.stats import rv_continuous, rv_discrete\n",
    "\n",
    "\n",
    "from src.data_processing import prepare_data\n",
    "from src.modeling import BayesianModel\n",
    "from src.inference import Inference\n",
    "from src.bayesian_node import BayesianNode, CategoricalNode\n",
    "from src.bayesian_network import BayesianNetwork\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from src.data_processing import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Determine environment and data path\n",
    "environment = os.getenv('ENVIRONMENT', 'local')\n",
    "data_path = os.getenv('LOCAL_DATA_PATH') if environment == 'local' else os.getenv('CLOUD_DATA_PATH')\n",
    "\n",
    "# File paths\n",
    "behavioral_path = os.path.join(data_path, 'connectome_behavioral.csv')\n",
    "hcp_path = os.path.join(data_path, 'hcp_freesurfer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_hcp = ['Gender', 'MMSE_Score', 'Age']\n",
    "\n",
    "behavioral_features = [\n",
    "    'Subject', 'Age', 'Gender', 'CogFluidComp_Unadj', 'CogCrystalComp_Unadj', 'MMSE_Score',\n",
    "    'NEOFAC_O', 'NEOFAC_C', 'ProcSpeed_Unadj', 'CardSort_Unadj', 'PicVocab_Unadj', 'ReadEng_Unadj'\n",
    "]\n",
    "\n",
    "hcp_features = [\n",
    "    'Subject', 'FS_TotCort_GM_Vol', 'FS_SubCort_GM_Vol', 'FS_Total_GM_Vol', 'FS_Tot_WM_Vol', 'FS_BrainStem_Vol',\n",
    "    'FS_L_Hippo_Vol', 'FS_R_Hippo_Vol', 'FS_L_Amygdala_Vol', 'FS_R_Amygdala_Vol',\n",
    "    'FS_L_Caudate_Vol', 'FS_R_Caudate_Vol', 'FS_L_Putamen_Vol', 'FS_R_Putamen_Vol',\n",
    "]\n",
    "\n",
    "categorical_columns = ['Gender', 'MMSE_Score', 'Age']\n",
    "\n",
    "prior_edges = [\n",
    "    ('Age', 'CogFluidComp_Unadj'),\n",
    "    ('Age', 'CogCrystalComp_Unadj'),\n",
    "    ('Age', 'MMSE_Score'),\n",
    "    ('Gender', 'CogFluidComp_Unadj'),\n",
    "    ('Gender', 'CogCrystalComp_Unadj'),\n",
    "    ('MMSE_Score', 'CogFluidComp_Unadj'),\n",
    "    ('MMSE_Score', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_Total_GM_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_Total_GM_Vol', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_Tot_WM_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_Tot_WM_Vol', 'CogCrystalComp_Unadj'),\n",
    "    ('FS_L_Hippo_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_R_Hippo_Vol', 'CogFluidComp_Unadj'),\n",
    "    ('FS_L_Amygdala_Vol', 'NEOFAC_O'),\n",
    "    ('FS_R_Amygdala_Vol', 'NEOFAC_O'),\n",
    "    ('NEOFAC_O', 'CogCrystalComp_Unadj'),\n",
    "    ('NEOFAC_C', 'CogFluidComp_Unadj'),\n",
    "    ('FS_L_Hippo_Vol', 'NEOFAC_O'),\n",
    "    ('FS_R_Hippo_Vol', 'NEOFAC_O'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, categorical_columns, categories = prepare_data(\n",
    "    behavioral_path=behavioral_path,\n",
    "    hcp_path=hcp_path,\n",
    "    behavioral_features=behavioral_features,\n",
    "    hcp_features=hcp_features,\n",
    "    categorical_columns=categorical_columns_hcp\n",
    "    )\n",
    "\n",
    "data = data.sample(n=200, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "model = BayesianModel(method='k2', max_parents=2, iterations=100, categorical_columns=categorical_columns)\n",
    "model.fit(data, prior_edges=prior_edges)\n",
    "\n",
    "# Access the Bayesian Network and Inference\n",
    "network = model.network\n",
    "inference = model.inference  # This should now be correctly initialized with nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute sensitivity using Inference class\n",
    "def compute_sensitivity(network: BayesianNetwork, target_node_name: str, num_samples: int = 1000) -> Dict[str, float]:\n",
    "    if target_node_name not in network.nodes:\n",
    "        raise ValueError(f\"Node {target_node_name} not found in the network.\")\n",
    "    \n",
    "    # Sample data for the target node\n",
    "    target_samples = inference.sample_node(target_node_name, num_samples)\n",
    "    \n",
    "    # Compute sensitivity\n",
    "    sensitivities = {}\n",
    "    for node_name, node in network.nodes.items():\n",
    "        if node_name == target_node_name:\n",
    "            continue\n",
    "        \n",
    "        # Sample for other nodes\n",
    "        other_samples = inference.sample_node(node_name, num_samples)\n",
    "        \n",
    "        # Compute sensitivity (example: mean difference or correlation)\n",
    "        sensitivity = np.mean(target_samples) - np.mean(other_samples)\n",
    "        sensitivities[node_name] = sensitivity\n",
    "    \n",
    "    return sensitivities\n",
    "\n",
    "# Example usage\n",
    "sensitivity = compute_sensitivity(network, \"CogFluidComp_Unadj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples for CogFluidComp_Unadj: [-0.67554348  0.49514762 -1.17323898 -0.56092195 -0.2473852   0.93143711\n",
      "  0.83485783  1.11600619 -0.47855965  0.67358212]\n"
     ]
    }
   ],
   "source": [
    "def sample_node_with_inference(node_name: str, size: int = 1) -> np.ndarray:\n",
    "    try:\n",
    "        samples = inference.sample_node(node_name, size)\n",
    "        return samples\n",
    "    except Exception as e:\n",
    "        print(f\"Error sampling node: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test sampling a node\n",
    "node_name = 'CogFluidComp_Unadj'\n",
    "samples = sample_node_with_inference(node_name, size=1000)\n",
    "\n",
    "if samples is not None:\n",
    "    print(f\"Samples for {node_name}: {samples[:10]}\")  # Print the first 10 samples\n",
    "else:\n",
    "    print(f\"Failed to sample node {node_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Initialization Check\n",
      "Node Name: FS_TotCort_GM_Vol, Type: BayesianNode\n",
      "Node Name: FS_SubCort_GM_Vol, Type: BayesianNode\n",
      "Node Name: FS_Total_GM_Vol, Type: BayesianNode\n",
      "Node Name: FS_Tot_WM_Vol, Type: BayesianNode\n",
      "Node Name: FS_BrainStem_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Hippo_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Hippo_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Amygdala_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Amygdala_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Caudate_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Caudate_Vol, Type: BayesianNode\n",
      "Node Name: FS_L_Putamen_Vol, Type: BayesianNode\n",
      "Node Name: FS_R_Putamen_Vol, Type: BayesianNode\n",
      "Node Name: Age, Type: BayesianNode\n",
      "Node Name: Gender, Type: BayesianNode\n",
      "Node Name: CogFluidComp_Unadj, Type: BayesianNode\n",
      "Node Name: CogCrystalComp_Unadj, Type: BayesianNode\n",
      "Node Name: MMSE_Score, Type: BayesianNode\n",
      "Node Name: NEOFAC_O, Type: BayesianNode\n",
      "Node Name: NEOFAC_C, Type: BayesianNode\n",
      "Node Name: ProcSpeed_Unadj, Type: BayesianNode\n",
      "Node Name: CardSort_Unadj, Type: BayesianNode\n",
      "Node Name: PicVocab_Unadj, Type: BayesianNode\n",
      "Node Name: ReadEng_Unadj, Type: BayesianNode\n",
      "\n",
      "Distributions Check\n",
      "Node FS_TotCort_GM_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_SubCort_GM_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_Total_GM_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_Tot_WM_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_BrainStem_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_L_Hippo_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_R_Hippo_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_L_Amygdala_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_R_Amygdala_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_L_Caudate_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_R_Caudate_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_L_Putamen_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node FS_R_Putamen_Vol has an unsupported distribution type: rv_continuous_frozen\n",
      "Node Age has an unsupported distribution type: rv_continuous_frozen\n",
      "Node Gender has an unsupported distribution type: rv_continuous_frozen\n",
      "Node CogFluidComp_Unadj has an unsupported distribution type: rv_continuous_frozen\n",
      "Node CogCrystalComp_Unadj has an unsupported distribution type: rv_continuous_frozen\n",
      "Node MMSE_Score has an unsupported distribution type: rv_continuous_frozen\n",
      "Node NEOFAC_O has an unsupported distribution type: rv_continuous_frozen\n",
      "Node NEOFAC_C has an unsupported distribution type: rv_continuous_frozen\n",
      "Node ProcSpeed_Unadj has an unsupported distribution type: rv_continuous_frozen\n",
      "Node CardSort_Unadj has an unsupported distribution type: rv_continuous_frozen\n",
      "Node PicVocab_Unadj has an unsupported distribution type: rv_continuous_frozen\n",
      "Node ReadEng_Unadj has an unsupported distribution type: rv_continuous_frozen\n",
      "\n",
      "Network Structure Check\n",
      "\n",
      "Inference Test\n",
      "Samples for CogFluidComp_Unadj: [ 0.05332731  0.60023215 -0.1250889   0.69294818 -0.45712585  0.44941586\n",
      " -0.48220469 -0.0266021  -0.62054507  1.23227149]\n",
      "Sensitivity for CogFluidComp_Unadj: {'FS_TotCort_GM_Vol': 0.08536705925564164, 'FS_SubCort_GM_Vol': 0.0959663316792154, 'FS_Total_GM_Vol': 0.0806194136282182, 'FS_Tot_WM_Vol': 0.1001395146802263, 'FS_BrainStem_Vol': -0.006216369027213363, 'FS_L_Hippo_Vol': 0.008856784950216336, 'FS_R_Hippo_Vol': 0.018175640114612767, 'FS_L_Amygdala_Vol': 0.09745974574687138, 'FS_R_Amygdala_Vol': 0.08975895542362637, 'FS_L_Caudate_Vol': -0.033863499021113415, 'FS_R_Caudate_Vol': 0.0312533720217775, 'FS_L_Putamen_Vol': 0.028253584152783846, 'FS_R_Putamen_Vol': 0.10449216683994653, 'Age': -1.1078050189920867, 'Gender': -0.3779754375826204, 'CogCrystalComp_Unadj': -0.10651875569677571, 'MMSE_Score': -29.04036311715196, 'NEOFAC_O': 0.00029535257176208085, 'NEOFAC_C': 0.10685680131227099, 'ProcSpeed_Unadj': -0.04629685878764198, 'CardSort_Unadj': -0.05351002698840685, 'PicVocab_Unadj': -0.05577662333821686, 'ReadEng_Unadj': -0.01884016629271764}\n"
     ]
    }
   ],
   "source": [
    "nodes = inference.nodes\n",
    "\n",
    "# 1. Verify Node Initialization\n",
    "print(\"Node Initialization Check\")\n",
    "for node_name, node in nodes.items():\n",
    "    if isinstance(node, BayesianNode):\n",
    "        print(f\"Node Name: {node_name}, Type: BayesianNode\")\n",
    "    else:\n",
    "        print(f\"Node Name: {node_name}, Type: {type(node).__name__}\")\n",
    "\n",
    "# 2. Check Distributions for Nodes\n",
    "print(\"\\nDistributions Check\")\n",
    "for node_name, node in nodes.items():\n",
    "    try:\n",
    "        distribution = node.get_distribution()\n",
    "        if isinstance(distribution, rv_continuous):\n",
    "            print(f\"Node Name: {node_name}\")\n",
    "            print(f\"Distribution: {distribution}\")\n",
    "            print(f\"Distribution Type: {type(distribution).__name__}\")\n",
    "            samples = distribution.rvs(size=10)  # Sample from the distribution\n",
    "            print(f\"Samples: {samples}\")\n",
    "        else:\n",
    "            print(f\"Node {node_name} has an unsupported distribution type: {type(distribution).__name__}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with node {node_name}: {e}\")\n",
    "\n",
    "# 3. Verify Network Structure\n",
    "print(\"\\nNetwork Structure Check\")\n",
    "try:\n",
    "    # Check if network structure is properly defined\n",
    "    for node_name, node in nodes.items():\n",
    "        if not hasattr(node, 'children'):\n",
    "            print(f\"Node {node_name} is missing 'children' attribute.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"Network Structure Error: {e}\")\n",
    "\n",
    "# 4. Test Inference Class\n",
    "print(\"\\nInference Test\")\n",
    "try:\n",
    "    # Test sampling from a node\n",
    "    node_name = 'CogFluidComp_Unadj'\n",
    "    try:\n",
    "        samples = inference.sample_node(node_name, size=10)\n",
    "        print(f\"Samples for {node_name}: {samples}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Sampling Error: {ve}\")\n",
    "    \n",
    "    # Test sensitivity computation (assuming compute_sensitivity function exists)\n",
    "    try:\n",
    "        sensitivity = compute_sensitivity(network, node_name)  # Ensure 'network' is defined\n",
    "        print(f\"Sensitivity for {node_name}: {sensitivity}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"Sensitivity Computation Error: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Inference Error: {e}\")\n",
    "\n",
    "# Note: Replace placeholder parts with actual implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
